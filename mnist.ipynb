{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "x_train.shape:  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('x_train.shape: ', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kentahara/.pyenv/versions/anaconda3-5.2.0/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From /Users/kentahara/.pyenv/versions/anaconda3-5.2.0/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 1.4543 - acc: 0.6609 - val_loss: 0.8044 - val_acc: 0.8244\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.6494 - acc: 0.8395 - val_loss: 0.5067 - val_acc: 0.8746\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.4771 - acc: 0.8746 - val_loss: 0.4076 - val_acc: 0.8929\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.4074 - acc: 0.8897 - val_loss: 0.3632 - val_acc: 0.9006\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.3705 - acc: 0.8976 - val_loss: 0.3357 - val_acc: 0.9069\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.3469 - acc: 0.9027 - val_loss: 0.3175 - val_acc: 0.9103\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.3300 - acc: 0.9072 - val_loss: 0.3057 - val_acc: 0.9127\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.3174 - acc: 0.9105 - val_loss: 0.2942 - val_acc: 0.9165\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.3065 - acc: 0.9125 - val_loss: 0.2871 - val_acc: 0.9154\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2982 - acc: 0.9145 - val_loss: 0.2786 - val_acc: 0.9187\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2904 - acc: 0.9168 - val_loss: 0.2722 - val_acc: 0.9205\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2832 - acc: 0.9184 - val_loss: 0.2671 - val_acc: 0.9220\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2772 - acc: 0.9193 - val_loss: 0.2620 - val_acc: 0.9240\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2716 - acc: 0.9212 - val_loss: 0.2569 - val_acc: 0.9247\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2665 - acc: 0.9230 - val_loss: 0.2553 - val_acc: 0.9258\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2617 - acc: 0.9239 - val_loss: 0.2518 - val_acc: 0.9278\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2571 - acc: 0.9251 - val_loss: 0.2486 - val_acc: 0.9281\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2525 - acc: 0.9266 - val_loss: 0.2445 - val_acc: 0.9298\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2481 - acc: 0.9279 - val_loss: 0.2407 - val_acc: 0.9302\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2438 - acc: 0.9288 - val_loss: 0.2358 - val_acc: 0.9314\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train / 255\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test = x_test / 255\n",
    "\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=64,\n",
    "        input_shape=(784,),\n",
    "        activation='relu',\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=10,\n",
    "        activation='softmax'\n",
    "    )\n",
    ")\n",
    "\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tsb = TensorBoard(log_dir='./logs_mnist')\n",
    "history_adam = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tsb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 42us/sample - loss: 1.5415 - acc: 0.5956 - val_loss: 0.8993 - val_acc: 0.7905\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.7256 - acc: 0.8171 - val_loss: 0.5619 - val_acc: 0.8621\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.5225 - acc: 0.8637 - val_loss: 0.4419 - val_acc: 0.8873\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.4361 - acc: 0.8832 - val_loss: 0.3837 - val_acc: 0.8948\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.3902 - acc: 0.8937 - val_loss: 0.3490 - val_acc: 0.9033\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.3613 - acc: 0.8997 - val_loss: 0.3285 - val_acc: 0.9084\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.3417 - acc: 0.9043 - val_loss: 0.3137 - val_acc: 0.9122\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.3271 - acc: 0.9075 - val_loss: 0.3015 - val_acc: 0.9144\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.3157 - acc: 0.9104 - val_loss: 0.2918 - val_acc: 0.9172\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.3059 - acc: 0.9123 - val_loss: 0.2852 - val_acc: 0.9175\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2976 - acc: 0.9144 - val_loss: 0.2794 - val_acc: 0.9193\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2908 - acc: 0.9165 - val_loss: 0.2735 - val_acc: 0.9221\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2842 - acc: 0.9184 - val_loss: 0.2667 - val_acc: 0.9222\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.2783 - acc: 0.9199 - val_loss: 0.2627 - val_acc: 0.9237\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2729 - acc: 0.9214 - val_loss: 0.2573 - val_acc: 0.9262\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2679 - acc: 0.9230 - val_loss: 0.2527 - val_acc: 0.9267\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2629 - acc: 0.9237 - val_loss: 0.2517 - val_acc: 0.9273\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.2583 - acc: 0.9257 - val_loss: 0.2472 - val_acc: 0.9302\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.2540 - acc: 0.9273 - val_loss: 0.2430 - val_acc: 0.9315\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s 37us/sample - loss: 0.2497 - acc: 0.9286 - val_loss: 0.2395 - val_acc: 0.9319\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input\n",
    "\n",
    "input = Input(shape=(784,))\n",
    "middle = Dense(units=64, activation='relu')(input)\n",
    "output = Dense(units=10, activation='softmax')(middle)\n",
    "model = Model(inputs=[input], outputs=[output])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "tsb = TensorBoard(log_dir='./logs_mnist_functional')\n",
    "history_adam = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tsb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
